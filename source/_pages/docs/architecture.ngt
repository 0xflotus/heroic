<h2>Architecture</h2>

<p>
  The following document will look at the architecture of a Heroic installation
  at scale.
</p>

<p>
  Heroic relies on technology which has been proved to operate at scale under
  the load that we expect such a system to receive.
</p>

<h3>Metric Transport: Kafka</h3>

<blockquote cite="http://kafka.apache.org/">
  <p>Kafka has a modern cluster-centric design that offers strong durability and
  fault-tolerance guarantees.</p>
  <footer><cite title="Source Title"><a href="http://kafka.apache.org/">http://kafka.apache.org/</a></cite></footer>
</blockquote>

<p>
  We primarily use Kafka for transporting metrics of each host (or instance),
  into Heroic.
  This translates into Heroic being a <em>push-based</em> system.
  Kafka also acts as an intermediate indirection layer, allowing you to perform
  system administration tasks on the consumers without causing disruptions on
  consumers.
</p>

<p>
  Because each <em>host</em> is reponsible for transporting the metrics, heroic
  does not have to perform any type of discovery, the first time a new
  time-series becomes visible in the pipeline it will be registered.
</p>

<h3>Storage: Cassandra</h3>

<p>
  Metrics are stored in Cassandra, or other typical column-based databases in a
  manner which avoids huge rows.
  The technique used is described in <a href="http://www.datastax.com/dev/blog/advanced-time-series-with-cassandra">Advanced Time Series with Cassandra</a>, and was inspired by how it's implemented in
  <a href="http://kairosdb.github.io/">KairosDB</a>.
</p>

<h3>Metadata: Elasticsearch</h3>

<p>
  We use Elasticsearch to store and make metadata available to a heroic
  cluster. It is the primary component that drives Heroic's <a ui-sref="docs.filter_dsl">filter DSL</a>.
</p>

<p>
  Elasticsearch has proven to have fairly significant stability concerns, but
  heroic uses it in a way so it acts as a non-primary storage and can rapidly be
  rebuilt.
</p>

<p>
  We also use Elasticsearch to drive <a ui-sref="docs.suggestions">suggestions</a>.
</p>

<h3>Federation</h3>

<p>
  Main article: <a ui-sref="^.federation">Federated Clusters</a>
</p>

<p>
  Heroic has support for federating requests, which allows multiple independant
  clusters to serve clients through a single, global interface.
  This can be used to reduce the amount of geographical traffic by allowing one
  cluster to operate completely within one datacenter.
</p>

<p>
  A client querying any heroic node in a federation will cause it to fan out to
  all <em>shards</em> that it knows about, process the request, and finally
  merge the result for the client.
</p>

<img style="width: 100%;" src="images/sharding.svg"></img>

<p>
  The system tries to be as transparent as possible in the face of problems,
  and for each request that fans out to a shard there is the potential that an
  error prevents the result from being computed.
</p>

<p>
  In the case of an unrecoverable error, the shards which were successfully queried will still return an result.
  The fact some shard is failing will be clearly communicated in the result.
  It will then be up to the client to decide how to manage that circumstance.
</p>

<img style="width: 100%;" src="images/errors.svg"></img>
